Loading fashion-mnist data...
Reading train-images-idx3-ubyte...Done
Reading train-labels-idx1-ubyte...Done
Reading t10k-images-idx3-ubyte...Done
Reading t10k-labels-idx1-ubyte...Done
mnist train number: 60000
mnist test number: 10000
0-th batch, loss: 2.30172
50-th batch, loss: 2.31116
100-th batch, loss: 2.10087
150-th batch, loss: 1.18628
200-th batch, loss: 2.29374
250-th batch, loss: 2.32471
300-th batch, loss: 2.32541
350-th batch, loss: 2.30535
400-th batch, loss: 2.30644
450-th batch, loss: 2.30747
500-th batch, loss: 2.30241
550-th batch, loss: 2.30447
600-th batch, loss: 2.30616
650-th batch, loss: 2.3134
700-th batch, loss: 2.30794
750-th batch, loss: 2.30683
800-th batch, loss: 2.30281
850-th batch, loss: 2.30263
900-th batch, loss: 2.3138
950-th batch, loss: 2.30386
1000-th batch, loss: 2.31725
1050-th batch, loss: 2.30135
1100-th batch, loss: 2.29967
1150-th batch, loss: 2.30363
1200-th batch, loss: 2.29849
1250-th batch, loss: 2.3039
1300-th batch, loss: 2.29839
1350-th batch, loss: 2.29889
1400-th batch, loss: 2.30216
1450-th batch, loss: 2.29308
1500-th batch, loss: 2.29533
1550-th batch, loss: 2.3064
1600-th batch, loss: 2.29747
1650-th batch, loss: 2.31393
1700-th batch, loss: 2.29649
1750-th batch, loss: 2.30748
1800-th batch, loss: 2.3086
1850-th batch, loss: 2.30643

1-st epoch, test acc: 0.1

0-th batch, loss: 2.30361
50-th batch, loss: 2.31124
100-th batch, loss: 2.29612
150-th batch, loss: 2.31111
200-th batch, loss: 2.30443
250-th batch, loss: 2.2973
300-th batch, loss: 2.294
350-th batch, loss: 2.30471
400-th batch, loss: 2.30645
450-th batch, loss: 2.30576
500-th batch, loss: 2.30516
550-th batch, loss: 2.30893
600-th batch, loss: 2.29938
650-th batch, loss: 2.29737
700-th batch, loss: 2.30482
750-th batch, loss: 2.29965
800-th batch, loss: 2.29167
850-th batch, loss: 2.30561
900-th batch, loss: 2.30002
950-th batch, loss: 2.30191
1000-th batch, loss: 2.30966
1050-th batch, loss: 2.3095
1100-th batch, loss: 2.30079
1150-th batch, loss: 2.30545
1200-th batch, loss: 2.29932
1250-th batch, loss: 2.30528
1300-th batch, loss: 2.31126
1350-th batch, loss: 2.30473
1400-th batch, loss: 2.30345
1450-th batch, loss: 2.30225
1500-th batch, loss: 2.3011
1550-th batch, loss: 2.30002
1600-th batch, loss: 2.30556
1650-th batch, loss: 2.30989
1700-th batch, loss: 2.3012
1750-th batch, loss: 2.30025
1800-th batch, loss: 2.30048
1850-th batch, loss: 2.30941

2-nd epoch, test acc: 0.1

0-th batch, loss: 2.30674
50-th batch, loss: 2.30234
100-th batch, loss: 2.29614
150-th batch, loss: 2.29537
200-th batch, loss: 2.3075
250-th batch, loss: 2.3057
300-th batch, loss: 2.31347
350-th batch, loss: 2.30665
400-th batch, loss: 2.29604
450-th batch, loss: 2.30371
500-th batch, loss: 2.29731
550-th batch, loss: 2.30268
600-th batch, loss: 2.31256
650-th batch, loss: 2.30619
700-th batch, loss: 2.30714
750-th batch, loss: 2.3016
800-th batch, loss: 2.29969
850-th batch, loss: 2.30178
900-th batch, loss: 2.29603
950-th batch, loss: 2.30058
1000-th batch, loss: 2.30281
1050-th batch, loss: 2.29716
1100-th batch, loss: 2.30286
1150-th batch, loss: 2.2986
1200-th batch, loss: 2.29397
1250-th batch, loss: 2.30996
1300-th batch, loss: 2.30341
1350-th batch, loss: 2.30373
1400-th batch, loss: 2.28928
1450-th batch, loss: 2.31664
1500-th batch, loss: 2.32706
1550-th batch, loss: 2.3016
1600-th batch, loss: 2.29842
1650-th batch, loss: 2.30442
1700-th batch, loss: 2.30634
1750-th batch, loss: 2.30431
1800-th batch, loss: 2.29928
1850-th batch, loss: 2.29464

3-rd epoch, test acc: 0.1

0-th batch, loss: 2.29572
50-th batch, loss: 2.29688
100-th batch, loss: 2.31089
150-th batch, loss: 2.31071
200-th batch, loss: 2.2893
250-th batch, loss: 2.3217
300-th batch, loss: 2.29985
350-th batch, loss: 2.3047
400-th batch, loss: 2.31244
450-th batch, loss: 2.30327
500-th batch, loss: 2.30324
550-th batch, loss: 2.29819
600-th batch, loss: 2.3097
650-th batch, loss: 2.30374
700-th batch, loss: 2.30066
750-th batch, loss: 2.30936
800-th batch, loss: 2.29833
850-th batch, loss: 2.2955
900-th batch, loss: 2.30482
950-th batch, loss: 2.3081
1000-th batch, loss: 2.29864
1050-th batch, loss: 2.31539
1100-th batch, loss: 2.30772
1150-th batch, loss: 2.29878
1200-th batch, loss: 2.30359
1250-th batch, loss: 2.3004
1300-th batch, loss: 2.28915
1350-th batch, loss: 2.29934
1400-th batch, loss: 2.30392
1450-th batch, loss: 2.30762
1500-th batch, loss: 2.30365
1550-th batch, loss: 2.30289
1600-th batch, loss: 2.30418
1650-th batch, loss: 2.31498
1700-th batch, loss: 2.29353
1750-th batch, loss: 2.29026
1800-th batch, loss: 2.31043
1850-th batch, loss: 2.29061

4-th epoch, test acc: 0.1

0-th batch, loss: 2.29927
50-th batch, loss: 2.3037
100-th batch, loss: 2.29908
150-th batch, loss: 2.30528
200-th batch, loss: 2.30181
250-th batch, loss: 2.29643
300-th batch, loss: 2.30508
350-th batch, loss: 2.30597
400-th batch, loss: 2.30203
450-th batch, loss: 2.30634
500-th batch, loss: 2.31644
550-th batch, loss: 2.31029
600-th batch, loss: 2.29695
650-th batch, loss: 2.29978
700-th batch, loss: 2.31441
750-th batch, loss: 2.29868
800-th batch, loss: 2.30113
850-th batch, loss: 2.30017
900-th batch, loss: 2.29676
950-th batch, loss: 2.30619
1000-th batch, loss: 2.31081
1050-th batch, loss: 2.2982
1100-th batch, loss: 2.30789
1150-th batch, loss: 2.30571
1200-th batch, loss: 2.29752
1250-th batch, loss: 2.30077
1300-th batch, loss: 2.29646
1350-th batch, loss: 2.3087
1400-th batch, loss: 2.3147
1450-th batch, loss: 2.31361
1500-th batch, loss: 2.30699
1550-th batch, loss: 2.30673
1600-th batch, loss: 2.31103
1650-th batch, loss: 2.30802
1700-th batch, loss: 2.30213
1750-th batch, loss: 2.29222
1800-th batch, loss: 2.30538
1850-th batch, loss: 2.29438

5-th epoch, test acc: 0.1

0-th batch, loss: 2.29991
50-th batch, loss: 2.29881
100-th batch, loss: 2.30513
150-th batch, loss: 2.29439
200-th batch, loss: 2.30106
250-th batch, loss: 2.30337
300-th batch, loss: 2.30021
350-th batch, loss: 2.28748
400-th batch, loss: 2.30482
450-th batch, loss: 2.30876
500-th batch, loss: 2.31317
550-th batch, loss: 2.31633
600-th batch, loss: 2.30177
650-th batch, loss: 2.29728
700-th batch, loss: 2.30532
750-th batch, loss: 2.28874
800-th batch, loss: 2.30512
850-th batch, loss: 2.30542
900-th batch, loss: 2.30191
950-th batch, loss: 2.30358
1000-th batch, loss: 2.30123
1050-th batch, loss: 2.3065
1100-th batch, loss: 2.303
1150-th batch, loss: 2.30542
1200-th batch, loss: 2.29911
1250-th batch, loss: 2.30255
1300-th batch, loss: 2.31276
1350-th batch, loss: 2.29871
1400-th batch, loss: 2.30383
1450-th batch, loss: 2.29633
1500-th batch, loss: 2.30033
1550-th batch, loss: 2.31015
1600-th batch, loss: 2.30299
1650-th batch, loss: 2.29525
1700-th batch, loss: 2.30988
1750-th batch, loss: 2.29632
1800-th batch, loss: 2.31771
1850-th batch, loss: 2.30941

6-th epoch, test acc: 0.1

0-th batch, loss: 2.29414
50-th batch, loss: 2.30835
100-th batch, loss: 2.30115
150-th batch, loss: 2.29578
200-th batch, loss: 2.30167
250-th batch, loss: 2.30105
300-th batch, loss: 2.31526
350-th batch, loss: 2.30332
400-th batch, loss: 2.29362
450-th batch, loss: 2.30436
500-th batch, loss: 2.31096
550-th batch, loss: 2.30469
600-th batch, loss: 2.30924
650-th batch, loss: 2.29864
700-th batch, loss: 2.30694
750-th batch, loss: 2.31764
800-th batch, loss: 2.30637
850-th batch, loss: 2.31324
900-th batch, loss: 2.30654
950-th batch, loss: 2.30511
1000-th batch, loss: 2.31095
1050-th batch, loss: 2.30176
1100-th batch, loss: 2.3017
1150-th batch, loss: 2.31308
1200-th batch, loss: 2.31029
1250-th batch, loss: 2.30707
1300-th batch, loss: 2.30764
1350-th batch, loss: 2.31173
1400-th batch, loss: 2.28927
1450-th batch, loss: 2.29801
1500-th batch, loss: 2.30316
1550-th batch, loss: 2.31672
1600-th batch, loss: 2.3043
1650-th batch, loss: 2.30447
1700-th batch, loss: 2.31627
1750-th batch, loss: 2.30409
1800-th batch, loss: 2.30462
1850-th batch, loss: 2.30506

7-th epoch, test acc: 0.1

0-th batch, loss: 2.29839
50-th batch, loss: 2.30631
100-th batch, loss: 2.30467
150-th batch, loss: 2.30941
200-th batch, loss: 2.30556
250-th batch, loss: 2.29945
300-th batch, loss: 2.32036
350-th batch, loss: 2.30349
400-th batch, loss: 2.29434
450-th batch, loss: 2.30564
500-th batch, loss: 2.30318
550-th batch, loss: 2.30647
600-th batch, loss: 2.30229
650-th batch, loss: 2.29216
700-th batch, loss: 2.29839
750-th batch, loss: 2.30027
800-th batch, loss: 2.29928
850-th batch, loss: 2.3062
900-th batch, loss: 2.30412
950-th batch, loss: 2.30365
1000-th batch, loss: 2.31491
1050-th batch, loss: 2.30319
1100-th batch, loss: 2.29526
1150-th batch, loss: 2.30225
1200-th batch, loss: 2.30128
1250-th batch, loss: 2.30754
1300-th batch, loss: 2.30049
1350-th batch, loss: 2.29581
1400-th batch, loss: 2.30897
1450-th batch, loss: 2.29803
1500-th batch, loss: 2.30014
1550-th batch, loss: 2.30745
1600-th batch, loss: 2.29974
1650-th batch, loss: 2.30606
1700-th batch, loss: 2.29131
1750-th batch, loss: 2.30335
1800-th batch, loss: 2.31559
1850-th batch, loss: 2.30206

8-th epoch, test acc: 0.1

0-th batch, loss: 2.29953
50-th batch, loss: 2.30409
100-th batch, loss: 2.30466
150-th batch, loss: 2.29235
200-th batch, loss: 2.30289
250-th batch, loss: 2.30792
300-th batch, loss: 2.30904
350-th batch, loss: 2.29936
400-th batch, loss: 2.29647
450-th batch, loss: 2.3095
500-th batch, loss: 2.30362
550-th batch, loss: 2.31273
600-th batch, loss: 2.31396
650-th batch, loss: 2.30583
700-th batch, loss: 2.30399
750-th batch, loss: 2.30804
800-th batch, loss: 2.29491
850-th batch, loss: 2.29975
900-th batch, loss: 2.29744
950-th batch, loss: 2.29841
1000-th batch, loss: 2.29922
1050-th batch, loss: 2.29372
1100-th batch, loss: 2.30755
1150-th batch, loss: 2.31031
1200-th batch, loss: 2.31242
1250-th batch, loss: 2.30195
1300-th batch, loss: 2.30644
1350-th batch, loss: 2.30506
1400-th batch, loss: 2.30555
1450-th batch, loss: 2.30269
1500-th batch, loss: 2.29973
1550-th batch, loss: 2.3032
1600-th batch, loss: 2.29766
1650-th batch, loss: 2.2969
1700-th batch, loss: 2.30712
1750-th batch, loss: 2.3041
1800-th batch, loss: 2.29679
1850-th batch, loss: 2.30066

9-th epoch, test acc: 0.1

0-th batch, loss: 2.30014
50-th batch, loss: 2.30596
100-th batch, loss: 2.30727
150-th batch, loss: 2.31386
200-th batch, loss: 2.30344
250-th batch, loss: 2.30617
300-th batch, loss: 2.2987
350-th batch, loss: 2.31355
400-th batch, loss: 2.2961
450-th batch, loss: 2.3092
500-th batch, loss: 2.30443
550-th batch, loss: 2.29874
600-th batch, loss: 2.30298
650-th batch, loss: 2.30172
700-th batch, loss: 2.30813
750-th batch, loss: 2.30913
800-th batch, loss: 2.3133
850-th batch, loss: 2.29242
900-th batch, loss: 2.30507
950-th batch, loss: 2.28995
1000-th batch, loss: 2.31221
1050-th batch, loss: 2.29226
1100-th batch, loss: 2.29761
1150-th batch, loss: 2.2924
1200-th batch, loss: 2.30658
1250-th batch, loss: 2.3128
1300-th batch, loss: 2.30024
1350-th batch, loss: 2.31653
1400-th batch, loss: 2.30616
1450-th batch, loss: 2.32089
1500-th batch, loss: 2.30101
1550-th batch, loss: 2.30166
1600-th batch, loss: 2.29488
1650-th batch, loss: 2.30999
1700-th batch, loss: 2.30651
1750-th batch, loss: 2.29663
1800-th batch, loss: 2.29785
1850-th batch, loss: 2.28973

10-th epoch, test acc: 0.1

